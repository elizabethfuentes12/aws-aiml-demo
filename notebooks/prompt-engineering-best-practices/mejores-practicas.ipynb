{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade boto3   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejores prácticas para diseñar prompts efectivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime', \n",
    "    region_name='us-east-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_bedrock(prompt):\n",
    "    response = bedrock_runtime.converse(\n",
    "    modelId=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"text\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "    inferenceConfig = {\n",
    "          \"temperature\":1,\n",
    "          \"maxTokens\":250,\n",
    "          \"topP\":0.999\n",
    "          }\n",
    "          )\n",
    "\n",
    "    try:\n",
    "        result = response['output']['message']['content'][0]['text'] \\\n",
    "        + '\\n--- Latency: ' + str(response['metrics']['latencyMs']) \\\n",
    "        + 'ms - Input tokens:' + str(response['usage']['inputTokens']) \\\n",
    "        + ' - Output tokens:' + str(response['usage']['outputTokens']) + ' ---\\n'\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = \"Output parsing error\"\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ser claro y conciso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=\"Escribe un haiku sobre robots\"\n",
    "result = api_bedrock(prompt1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=\"\"\"¿Escribe un haiku sobre robots. \n",
    "            Omite el preámbulo y pasa directamente al poema.\"\"\"\n",
    "result = api_bedrock(prompt2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incluya contexto si es necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Amazon Q Developer is a generative artificial intelligence (AI) \n",
    "powered conversational assistant that can help you understand, build, extend, \n",
    "and operate AWS applications. You can ask questions about AWS architecture, \n",
    "your AWS resources, best practices, documentation, support, and more. \n",
    "Amazon Q is constantly updating its capabilities so your questions get \n",
    "the most contextually relevant and actionable answers.\n",
    "\n",
    "When used in an integrated development environment (IDE), Amazon Q provides \n",
    "software development assistance. Amazon Q can chat about code, provide inline \n",
    "code completions, generate net new code, scan your code for security vulnerabilities, \n",
    "and make code upgrades and improvements, such as language updates, debugging, and optimizations.\n",
    "\n",
    "Amazon Q is powered by Amazon Bedrock, a fully managed service that makes \n",
    "foundation models (FMs) available through an API. The model that powers Amazon Q \n",
    "has been augmented with high quality AWS content to get you more complete, actionable, \n",
    "and referenced answers to accelerate your building on AWS.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=\"Resumeme el articulo: \"+text\n",
    "result = api_bedrock(prompt1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=\"Proporcione un resumen de este artículo para utilizarlo en una publicación de blog: \"+text\n",
    "result = api_bedrock(prompt2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USA XML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Amazon Q Developer is a generative artificial intelligence (AI) \n",
    "powered conversational assistant that can help you understand, build, extend, \n",
    "and operate AWS applications. You can ask questions about AWS architecture, \n",
    "your AWS resources, best practices, documentation, support, and more. \n",
    "Amazon Q is constantly updating its capabilities so your questions get \n",
    "the most contextually relevant and actionable answers.\n",
    "\n",
    "When used in an integrated development environment (IDE), Amazon Q provides \n",
    "software development assistance. Amazon Q can chat about code, provide inline \n",
    "code completions, generate net new code, scan your code for security vulnerabilities, \n",
    "and make code upgrades and improvements, such as language updates, debugging, and optimizations.\n",
    "\n",
    "Amazon Q is powered by Amazon Bedrock, a fully managed service that makes \n",
    "foundation models (FMs) available through an API. The model that powers Amazon Q \n",
    "has been augmented with high quality AWS content to get you more complete, actionable, \n",
    "and referenced answers to accelerate your building on AWS.\"\"\"\n",
    "RED_SOCIAL = \"linkedin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=f\"\"\" Eres un experto en publicidad en redes sociales, te entregan el texto y la red social y creas la publicidad. \n",
    "<texto>{text}</texto>\n",
    "<red_social>{RED_SOCIAL}</red_social>\n",
    "\"\"\"\n",
    "result = api_bedrock(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=f\"\"\" Clasifique el texto en neutro, negativo o positivo.\n",
    "Texto: Creo que Mazatlán esta increíble.\n",
    "Sentimiento:\n",
    "\"\"\"\n",
    "result = api_bedrock(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=f\"\"\" Clasificar reseñas de restaurantes como positivas o negativas.\n",
    "\n",
    "Reseña: La comida estaba deliciosa y el servicio fue excelente.\n",
    "Clasificación: Positiva\n",
    "\n",
    "Reseña: El lugar estaba sucio y la comida fría.\n",
    "Clasificación: Negativa\n",
    "\n",
    "Reseña: Precios razonables y ambiente agradable.\n",
    "Clasificación:\n",
    "\"\"\"\n",
    "result = api_bedrock(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain-of-thought prompting\n",
    "## Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=f\"\"\"Problema:\n",
    "En una fiesta de la Pycon, hay 3 pizzas grandes. Cada pizza está cortada en 8 rebanadas. Si hay 12 invitados y cada uno come 2 rebanadas, ¿cuántas rebanadas de pizza sobrarán?\n",
    "\n",
    "Instrucción:\n",
    "Resuelve este problema pensando paso a paso. Muestra tu razonamiento en cada etapa.\n",
    "\n",
    "\"\"\"\n",
    "result = api_bedrock(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain-of-thought prompting\n",
    "## Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=f\"\"\"Tarea: Calcular cuántos tacos puede comer un programador en una noche de coding.\n",
    "Datos: 3 horas de coding, 1 bug resuelto\n",
    "Pensamiento: \n",
    "1. Base: 3 tacos/hora x 3 horas = 9 tacos \n",
    "2. Bonus por bug: +2 tacos\n",
    "Total: 11 tacos\n",
    "Datos: 2 horas de coding, 1 feature completada\n",
    "Pensamiento: \n",
    "1. Base: 3 tacos/hora x 2 horas = 6 tacos\n",
    "2. Bonus por feature: +3 tacos\n",
    "Total: 9 tacos\n",
    "\n",
    "Datos: 4 horas de coding, 2 bugs resueltos, 1 crash del sistema:\n",
    "\n",
    "\"\"\"\n",
    "result = api_bedrock(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilice directivas para el tipo de respuesta deseado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=\"¿Cuál es la capital de Nueva York? Proporcione la respuesta en una oración completa.\"\n",
    "result = api_bedrock(prompt1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=\"¿Cuál es la capital de Nueva York?\"\n",
    "result = api_bedrock(prompt2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considere el resultado en el mensaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=\"Calcula el área de un círculo con un radio de 3 pulgadas\"\n",
    "api_bedrock(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=\"Calcula el área de un círculo con un radio de 3 pulgadas (7,5 cm). Redondea tu respuesta al número entero más cercano.\"\n",
    "api_bedrock(prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciar mensajes con una pregunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evento = \"\"\" En septiembre de 1666, un pequeño incendio comenzó en la panadería del panadero Thomas Farriner en Pudding Lane, en Londres. Sin embargo, debido a las condiciones secas y al viento fuerte, el fuego se extendió rápidamente a través de las casas de madera apiñadas en la ciudad. Dentro de pocas horas, el fuego se había extendido desde Pudding Lane hasta la catedral de San Pablo. Al día siguiente, el fuego había arrasado la mayor parte de la ciudad dentro de las murallas. Durante casi una semana, el fuego ardió sin control. Solo se detuvo cuando el viento cambió de dirección y los esfuerzos para demoler edificios crearon calles de fuego para detener su propagación.\n",
    "Cuando finalmente terminó, el Gran Incendio de Londres había destruido 13,200 casas, 87 iglesias parroquiales, St. Paul's Cathedral y muchos edificios gubernamentales. Se estima que la pérdida de vidas humanas fue de solo unas pocas docenas, pero decenas de miles de londinenses se quedaron sin hogar. Fue uno de los peores desastres en la historia de Inglaterra. El incendio tuvo un impacto duradero en Londres y en Inglaterra. Sirvió para impulsar la reconstrucción de Londres con amplias calles y edificios de piedra en lugar de madera, reduciendo así el riesgo de futuros incendios a gran escala. También llevó a la creación del London Building Acts, uno de los primeros códigos de construcción del mundo.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1= \"¿Por qué ocurrió el evento en los tags <evento></evento>? Explícalo en tres frases. <evento>\"+evento+\"</evento>\"\n",
    "\n",
    "api_bedrock(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2= \"Resume  el evento en los tags <evento></evento>. <evento>\"+evento+\"</evento>\"\n",
    "\n",
    "api_bedrock(prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proporcione una respuesta de ejemplo (one shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_negativo =  \"\"\"Compré el nuevo teléfono X pero ha sido una decepción total. La batería dura apenas unas horas y la cámara toma fotos borrosas. Además se cuelga constantemente. No puedo recomendar este producto.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1= \"Determine el sentimiento de esta publicación en las redes sociales:\"+review_negativo\n",
    "api_bedrock(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = f\"\"\"Determine el sentimiento de la siguiente publicación en las redes sociales utilizando estos ejemplos:\n",
    "post: “Muy buen producto, me encanta.” sentimiento: Positivo\n",
    "post: “Odio cuando se agota la batería de mi teléfono.” sentimiento:  Negativo\n",
    "post: \"{review_negativo}\" sentimiento:  \"\"\"\n",
    "api_bedrock(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
